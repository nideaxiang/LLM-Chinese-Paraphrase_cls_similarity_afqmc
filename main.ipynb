{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a75266",
   "metadata": {},
   "source": [
    "# 版本2.0\n",
    "- 模型：bert-base-chinese\n",
    "- 数据集：蚂蚁金融语义相似度数据集 AFQMC 作为语料，提供了官方的数据划分，训练集 / 验证集 / 测试集分别包含 34334 / 4316 / 3861 个句子对，标签 0 表示非同义句，1 表示同义句：\n",
    "- 数据集格式：json\n",
    "- 任务：二分类\n",
    "- 指标：accuracy,f1\n",
    "### 特点：\n",
    "- 手撕\n",
    "- 定义数据集进行数据加载\n",
    "- 继承了BertForSequenceClassification模型来写模型\n",
    "- 定义了损失函数和优化器\n",
    "- 定义了训练循环和评估循环\n",
    "\n",
    "### 由于GPU的原因，只选取了训练集的前8000个样本进行训练，可以修改max_samples参数来改变训练样本的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2284a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\Anaconda\\envs\\LLM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb89eb",
   "metadata": {},
   "source": [
    "# 1. 定义数据集并进行一次性读取\n",
    "- strip()的必要性在于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
    "大多数情况都会有：\n",
    "line == '{\"a\": 1, \"b\": 2}\\n'\n",
    "- enumerate(f) 本质是：对文件对象按行迭代，同时给每一行加一个自增编号\n",
    "- for idx, line in enumerate(f):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| 变量     | 含义             |\n",
    "| ------ | -------------- |\n",
    "| `idx`  | 当前是第几行（从 0 开始） |\n",
    "| `line` | 当前这一行的字符串内容    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be07459",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFQMC(Dataset):\n",
    "    def __init__(self,data_path,max_samples=5000):\n",
    "        self.data = self.load_data(data_path,max_samples)\n",
    "    def load_data(self,data_path,max_samples=5000):\n",
    "        data = {}\n",
    "        with open(data_path,'r',encoding='utf-8') as f:\n",
    "            #以文本模式读取json \n",
    "            #单条加载\n",
    "            for idx, line in enumerate(f):\n",
    "                if idx >= max_samples:          # 只取前 max_samples 条\n",
    "                    break\n",
    "                #strip()方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
    "                #loads()传入的是一个字符串，返回一个python对象\n",
    "                sample = json.loads(line.strip())\n",
    "                data[idx] = sample\n",
    "        return data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        sample = self.data[idx]\n",
    "        return sample\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "725baf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=AFQMC('./afqmc_public/train.json',max_samples=8000)\n",
    "#取训练数据的前3000条\n",
    "\n",
    "valdata=AFQMC('./afqmc_public/dev.json',max_samples=3000)\n",
    "#取验证数据的前1000条\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a742d",
   "metadata": {},
   "source": [
    "##### 对于特别大的数据集，难以一次性加载到内存中\n",
    "- 解决方法：使用可迭代数据集（IterableDataset）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f3ed00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class IterableAFQMC(IterableDataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data_file = data_file\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.data_file, 'rt') as f:\n",
    "            for line in f:\n",
    "                sample = json.loads(line.strip())\n",
    "                yield sample\n",
    "\n",
    "#train_data = IterableAFQMC('data/afqmc_public/train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fdb843",
   "metadata": {},
   "source": [
    "# 2. 加载到dataloader中并进行分词处理 \n",
    "- 按 batch 切分后的“批次迭代器”dataloader 并预处理\n",
    "- 需要把内容和标签都转为tensor\n",
    "- 需要加载预训练的bert-base-chines的checkpoint作为分词器\n",
    "- 每个batch包括input_ids, attention_mask, token_type_ids, labels四个特征，但每个特征的维度都是(batch_size, max_seq_len)\n",
    "- max_seq_len是动态填充的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "checkpoint = \"bert-base-chinese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_sen1=[]\n",
    "    batch_sen2=[]\n",
    "    batch_labels=[]\n",
    "    for example in batch:\n",
    "        batch_sen1.append(example[\"sentence1\"])\n",
    "        batch_sen2.append(example[\"sentence2\"])\n",
    "        batch_labels.append(int(example[\"label\"]))#从字符串转换为整数\n",
    "    tokenized_batch = tokenizer(        \n",
    "        batch_sen1,\n",
    "        batch_sen2,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    tokenized_batch[\"labels\"] = torch.tensor(batch_labels) #将列表转换为张量\n",
    "    return tokenized_batch\n",
    "#创建train_dataloader传入traindata和collate_fn\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db241a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "        traindata,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "valid_dataloader= DataLoader(valdata, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c85a1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 5709, 1446, 7583, 2428,  802,  749, 6820, 1377,  809, 4500, 1408,\n",
       "          102, 1963, 3362, 2769, 6206, 3118,  802, 4638, 7032, 7583, 6631, 6814,\n",
       "         5709, 1446, 7583, 2428, 6820, 1377,  809, 4500, 5709, 1446,  720,  102,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2990, 4850, 2644, 4638, 6572, 2787, 3257, 3198,  679, 5016, 1394,\n",
       "         2458, 6858, 3118,  802, 2140, 5709, 1446,  928, 4500, 1305, 3119, 7178,\n",
       "          102, 2458, 6858, 5709, 1446,  928, 4500, 1305, 8024, 3119, 3621, 2990,\n",
       "         4850, 6572, 2787, 7444, 6206,  784,  720, 3340,  816,  102],\n",
       "        [ 101, 2769, 4638, 5709, 1446, 4500, 1071,  800, 3175, 2466, 2582,  720,\n",
       "         6820, 3621,  102, 2582,  720, 6820, 1762, 5709, 1446, 2521, 6820, 3621,\n",
       "         7027,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2769, 5709, 1446, 6874, 3309,  749, 8024, 6820, 3621, 1400,  511,\n",
       "         5709, 1446, 6158, 1108, 5310,  749, 8024, 3221, 2582,  720, 1726,  752,\n",
       "          102, 5709, 1446, 6874, 3309, 6158, 1108, 5310, 6820,  833, 7028, 3173,\n",
       "         6237, 1108,  886, 4500, 1408,  102,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), 'labels': tensor([0, 0, 0, 0])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看train_dataloader的第一个batch\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7777e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 42])\n",
      "torch.Size([4, 42])\n",
      "torch.Size([4, 42])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "#打印各个特征的shape\n",
    "for batch in train_dataloader:\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    print(batch[\"attention_mask\"].shape)\n",
    "    print(batch[\"token_type_ids\"].shape)\n",
    "    print(batch[\"labels\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeea058",
   "metadata": {},
   "source": [
    "如上，按照4个样本一个批次进行编码,每次的长度都不同，因为自动对每个 batch 中的样本进行补全和截断，**这种只在一个 batch 内进行补全的操作被称为动态补全 (Dynamic padding)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75081eda",
   "metadata": {},
   "source": [
    "# 3.构建模型并进行训练\n",
    "- 先前使用的是AutoModelForSequenceClassification 类来完成。\n",
    "- 在这里我们自己利用transformer库或BertForSequenceClassification类继承进行编写\n",
    "    以Bert双向编码器为底座，任务类型是成对处理，只用 BERT 的“[CLS]”class token 向量来做下游决策，取最后一层 [CLS] 对应的 768 维（或 1024 维）向量，就能当整段文本的“句向量”用，再接个全连接层就能做分类或打分。\n",
    "- 所以取最后一层 [CLS] 对应的向量，作为整段文本的“句向量”，再接个全连接层，就能做分类或打分。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983c971",
   "metadata": {},
   "source": [
    "### 1)继承Module类的写法，本质上在结构上增加一个model head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbb07208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForPairwiseCLS(\n",
       "  (bert_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "class BertForPairwiseCLS(nn.Module):\n",
    "    def __init__(self,dropout_prob=0.1):\n",
    "        super(BertForPairwiseCLS,self).__init__()\n",
    "        # 加载预训练的BERT模型\n",
    "        self.bert_encoder=AutoModel.from_pretrained(checkpoint)\n",
    "        #手动添加dropout层和分类层\n",
    "        self.dropout=nn.Dropout(dropout_prob)\n",
    "        self.classifier=nn.Linear(768,2)\n",
    "    def forward(self,x):\n",
    "        bert_output=self.bert_encoder(**x) #传入的x是一个字典，包含了输入的文本和注意力掩码\n",
    "        cls_output=bert_output.last_hidden_state[:,0,:] #取最后一层隐藏层的第一个token的输出，即[CLS]对应的向量\n",
    "        cls_output=self.dropout(cls_output)\n",
    "        logits=self.classifier(cls_output)\n",
    "        return logits\n",
    "\n",
    "model=BertForPairwiseCLS().to(device)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38688087",
   "metadata": {},
   "source": [
    "来描述下模型中数据的变化维度：\n",
    "- 初始输入\n",
    "    text_a = \"怎么查话费\"  \n",
    "    text_b = \"如何查询手机余额\"  \n",
    "- 分词后：inputs = tokenizer(text_a, text_b, return_tensors='pt') 后\n",
    "    维度是(1, 128)，其中128是最大序列长度，padding后的序列长度\n",
    "    按照batch_size=4加载，则维度是(4, 128)\n",
    "- embedding后：经过嵌入层后，维度是(4, 128, 768)，其中4是batch_size，12 8是最大序列长度，768是BERT的隐藏层维度\n",
    "- 经过模型计算：\n",
    "    经过注意力计算后对最后一层隐藏层的输出，维度是(4, 128, 768)\n",
    "- 线性变换得到logits，维度是(4, 2)，其中2是分类数\n",
    "- 对logits进行softmax，维度不变，得到每个类别的概率分布\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec10477e",
   "metadata": {},
   "source": [
    "## 2)继承BERT 模型（BertPreTrainedModel 类）的写法\n",
    "- 所有参数都被继承了，包括模型的结构、参数、方法等\n",
    "- 并可在config中自定义模型的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb540de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForPairwiseCLS2(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import BertPreTrainedModel,BertModel\n",
    "from transformers import AutoConfig\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class BertForPairwiseCLS2(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config,add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(768, 2)\n",
    "        self.post_init()\n",
    "    def forward(self,x):\n",
    "        bert_outputs=self.bert(**x)\n",
    "        cls_output=bert_outputs.last_hidden_state[:,0,:]\n",
    "        cls_output=self.dropout(cls_output)\n",
    "        logits=self.classifier(cls_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "config=AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "model=BertForPairwiseCLS2(config)\n",
    "model.to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34fb945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "#将一个 Batch 的数据送入模型\n",
    " #先去掉labels\n",
    "batch.pop('labels', None)   # 或者 del batch['labels']\n",
    "y=model(batch)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b3df6",
   "metadata": {},
   "source": [
    "## 3）训练模型（微调参数）\n",
    "- 学习率需要动态性：大学习率负责“快速找到大致正确的区域”，小学习率负责“在好区域里精细收敛”。\n",
    "- 如果全程都用一个固定学习率：\n",
    "    太大 → 来回震荡，收不住\n",
    "    太小 → 走得太慢，甚至走不出局部差解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d6a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for step,batch in enumerate(train_dataloader,start=1):\n",
    "        batch=batch.to(device)\n",
    "        y=batch.pop('labels', None) \n",
    "        print(y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "381ea335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm # 用于显示训练进度条\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader,model,loss_fn,optimizer,scheduler,epoch,total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_step_num = (epoch-1)*len(dataloader)\n",
    "\n",
    "    model.train()\n",
    "    for step,batch in enumerate(dataloader,start=1):\n",
    "        batch=batch.to(device)\n",
    "        y=batch.pop('labels', None) \n",
    "        pred=model(batch)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad() # 清空梯度\n",
    "        loss.backward() # 计算梯度\n",
    "        optimizer.step() # 更新模型参数\n",
    "        scheduler.step() # 更新学习率,动态调整学习率\n",
    "\n",
    "        total_loss += loss.item() # 累加损失\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_step_num + step):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss\n",
    "\n",
    "def test_loop(dataloader, model, mode='Valid'):\n",
    "    assert mode in ['Test', 'Valid'], \"mode must be 'Test' or 'Valid'\"\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch=batch.to(device)\n",
    "            y=batch.pop('labels', None) \n",
    "            pred=model(batch)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    correct /= size\n",
    "    print(f\"{mode} Accuracy: {(100*correct):>0.1f}%\")\n",
    "    return correct\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "804181ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ee7ab",
   "metadata": {},
   "source": [
    "默认情况下，优化器会线性衰减学习率，对于上面的例子，学习率会线性地从 5e-5\n",
    " 降到 0。\n",
    "- 为了正确地定义学习率调度器，我们需要知道总的训练步数 (step)，它等于训练轮数 (Epoch number) 乘以每一轮中的步数（也就是训练 dataloader 的大小）：\n",
    "因为每一步都会调用优化器，所以整个训练过程中，优化器会被调用多少次 optimizer.step()，也就是学习率会被更新多少次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c799b73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindata 有 8000 个样本\n",
      "train_dataloader 有 2000 个 batch\n",
      "更新学习率需要 6000 步\n"
     ]
    }
   ],
   "source": [
    "# 计算这个训练过程需要的总步数\n",
    "#len(train_dataloader) 已经“除过 batch_size 了\n",
    "# ”DataLoader 的本质是：\n",
    "# 把样本按 batch_size 切分后，形成一个 batch 的序列\n",
    "\n",
    "print(f\"traindata 有 {len(traindata)} 个样本\")\n",
    "epochs = 3\n",
    "print(f\"train_dataloader 有 {len(train_dataloader)} 个 batch\")\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "\n",
    "print(f\"更新学习率需要 {num_training_steps} 步\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a28f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在这么多step，可以使得学习率线性地从初始 lr 下降到 0\n",
    "from transformers import get_scheduler\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38582b64",
   "metadata": {},
   "source": [
    "将”训练循环”和”验证/测试循环”组合成 Epoch，就可以进行模型的训练和验证了\n",
    "- 每个 Epoch 包含一个训练循环和一个验证/测试循环\n",
    "- 训练循环用于更新模型参数，验证/测试循环用于评估模型性能\n",
    "- 每个 Epoch 结束后，根据验证/测试准确率选择最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "370d2084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.669757:   9%|▉         | 182/2000 [00:11<01:52, 16.22it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch_num):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mep\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test_loop(valid_dataloader, model, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_acc \u001b[38;5;241m<\u001b[39m test_acc:\n",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, scheduler, epoch, total_loss)\u001b[0m\n\u001b[0;32m      8\u001b[0m batch\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m y\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \n\u001b[1;32m---> 10\u001b[0m pred\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# 清空梯度\u001b[39;00m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m, in \u001b[0;36mBertForPairwiseCLS2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 16\u001b[0m     bert_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx)\n\u001b[0;32m     17\u001b[0m     cls_output\u001b[38;5;241m=\u001b[39mbert_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[0;32m     18\u001b[0m     cls_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(cls_output)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\software\\Anaconda\\envs\\LLM\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:966\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    959\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_causal_attention_mask_for_sdpa(\n\u001b[0;32m    960\u001b[0m             attention_mask,\n\u001b[0;32m    961\u001b[0m             input_shape,\n\u001b[0;32m    962\u001b[0m             embedding_output,\n\u001b[0;32m    963\u001b[0m             past_key_values_length,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_length\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[0;32m    972\u001b[0m     extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)\n",
      "File \u001b[1;32md:\\software\\Anaconda\\envs\\LLM\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:457\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[1;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAttentionMaskConverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_expand_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_len\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\Anaconda\\envs\\LLM\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:196\u001b[0m, in \u001b[0;36mAttentionMaskConverter._expand_mask\u001b[1;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[0;32m    192\u001b[0m tgt_len \u001b[38;5;241m=\u001b[39m tgt_len \u001b[38;5;28;01mif\u001b[39;00m tgt_len \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m src_len\n\u001b[0;32m    194\u001b[0m expanded_mask \u001b[38;5;241m=\u001b[39m mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m1\u001b[39m, tgt_len, src_len)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m--> 196\u001b[0m inverted_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexpanded_mask\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inverted_mask\u001b[38;5;241m.\u001b[39mmasked_fill(inverted_mask\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool), torch\u001b[38;5;241m.\u001b[39mfinfo(dtype)\u001b[38;5;241m.\u001b[39mmin)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.669757:   9%|▉         | 183/2000 [00:26<01:52, 16.22it/s]"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "learning_rate = 1e-5\n",
    "epoch_num = 3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_loss = 0.\n",
    "best_acc = 0.\n",
    "\n",
    "for ep in range(epoch_num):\n",
    "    print(f\"Epoch {ep+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, loss_fn, optimizer, lr_scheduler, ep+1, total_loss)\n",
    "    test_acc = test_loop(valid_dataloader, model, mode='Valid')\n",
    "    \n",
    "    if best_acc < test_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), f'epoch_{ep+1}_valid_acc_{(100*test_acc):0.1f}_model_weights.bin')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f543cc6",
   "metadata": {},
   "source": [
    "最终准确率在67.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d165a08",
   "metadata": {},
   "source": [
    "# 4.加载模型并报告最终准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a66a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('epoch_3_valid_acc_74.1_model_weights.bin'))\n",
    "test_loop(valid_dataloader, model, mode='Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
